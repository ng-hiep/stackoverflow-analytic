{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName('Access GCS') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark._jsc.hadoopConfiguration() \\\n",
    "    .set(\"google.cloud.auth.service.account.json.keyfile\",\"/.google/credentials/google_credentials_project.json\")\n",
    "\n",
    "\n",
    "BUCKET = os.getenv('GCP_GCS_BUCKET')\n",
    "PROJECT = os.getenv('GCP_PROJECT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_bigquery(table, date):\n",
    "    path = f\"gs://{BUCKET}/BigQuery/{table}-{date}/*.parquet\"\n",
    "    df = spark.read.parquet(path, header = True)\n",
    "    df.write.format('bigquery') \\\n",
    "      .option('table', 'wordcount_dataset.wordcount_output') \\\n",
    "      .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Initialise a client\n",
    "storage_client = storage.Client(\"DE-stack-overflow\")\n",
    "# Create a bucket object for our bucket\n",
    "bucket = storage_client.get_bucket('dtc_data_lake_de-stack-overflow')\n",
    "# all files in the bucket \n",
    "files = list(bucket.list_blobs())\n",
    "files = [blob.name for blob in files if 'BigQuery/' in blob.name]\n",
    "files = [file for file in files if '.parquet' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['badges', 'posts_questions', 'posts_answers', 'users']\n",
    "total = 0\n",
    "for table in tables:\n",
    "    uris = [f'gs://{BUCKET}/'+ file for file in files if table in file]\n",
    "    total += len(uris)/4\n",
    "    print(table, len(uris)/4)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = rf\"gs://{BUCKET}/BigQuery/posts_questions-*/*.parquet\"\n",
    "df = spark.read.parquet(path, header = True)\n",
    "\n",
    "df.createOrReplaceTempView('posts_questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the percentage of questions that have been answered over the years?\n",
    "spark.sql('''\n",
    "SELECT\n",
    "  EXTRACT(YEAR FROM creation_date) AS Year,\n",
    "  COUNT(*) AS Number_of_Questions,\n",
    "  ROUND(100 * SUM(IF(answer_count > 0, 1, 0)) / COUNT(*), 1) AS Percent_Questions_with_Answers\n",
    "FROM\n",
    "  posts_questions\n",
    "GROUP BY\n",
    "  Year\n",
    "ORDER BY\n",
    "  Year\n",
    "    ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_users=rf\"gs://{BUCKET}/BigQuery/users-*/*.parquet\"\n",
    "df_users = spark.read.parquet(path_users, header = True)\n",
    "path_badges=rf\"gs://{BUCKET}/BigQuery/badges-*/*.parquet\"\n",
    "df_badges = spark.read.parquet(path_badges, header = True)\n",
    "path_answers=rf\"gs://{BUCKET}/BigQuery/posts_answers-*/*.parquet\"\n",
    "df_answers = spark.read.parquet(path_answers, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.createOrReplaceTempView('users')\n",
    "df_badges.createOrReplaceTempView('badges')\n",
    "df_answers.createOrReplaceTempView('posts_answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the reputation and badge count of users across different tenures on StackOverflow?\n",
    "Q4 = spark.sql('''\n",
    "SELECT user_Tenure,\n",
    "       COUNT(1) AS Num_Users,\n",
    "       ROUND(AVG(reputation)) AS Avg_Reputation,\n",
    "       ROUND(AVG(num_badges)) AS Avg_Num_Badges\n",
    "FROM (\n",
    "  SELECT users.id AS user,\n",
    "          ROUND(EXTRACT(DAY FROM CURRENT_TIMESTAMP()-MIN(users.creation_date))/365) AS user_tenure,\n",
    "         MIN(users.reputation) AS reputation,\n",
    "         SUM(IF(badges.user_id IS NULL, 0, 1)) AS num_badges\n",
    "  FROM users\n",
    "  LEFT JOIN badges\n",
    "  ON users.id = badges.user_id\n",
    "  GROUP BY user\n",
    ")\n",
    "GROUP BY User_Tenure\n",
    "ORDER BY User_Tenure\n",
    "    ''')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
